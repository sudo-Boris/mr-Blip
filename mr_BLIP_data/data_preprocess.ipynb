{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4204c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# tqdm for notebooks\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e807f09",
   "metadata": {},
   "source": [
    "# create folder for each dataset first    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09845339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    # if no such directory, create one\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(json.dumps(content))\n",
    "\n",
    "\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]\n",
    "\n",
    "\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7083bf5",
   "metadata": {},
   "source": [
    "# qvh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"Your/path/to/QVHighlights\"\n",
    "train_path = ann_root + \"/highlight_train_release.jsonl\"\n",
    "val_path = ann_root + \"/highlight_val_release.jsonl\"\n",
    "test_path = ann_root + \"/highlight_test_release.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_jsonl(train_path)\n",
    "val = load_jsonl(val_path)\n",
    "test = load_jsonl(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d681ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_QVH(data, relative_time=False, save_float=False, is_test=False):\n",
    "    out = []\n",
    "    for d in data:\n",
    "        sample = {}\n",
    "        sample[\"video\"] = d[\"vid\"]\n",
    "        sample[\"qid\"] = \"QVHighlight_\" + str(d[\"qid\"])\n",
    "        sample[\"query\"] = d[\"query\"]\n",
    "        duration = d[\"duration\"]\n",
    "        sample[\"duration\"] = duration\n",
    "\n",
    "        if not is_test:\n",
    "            windows = d[\"relevant_windows\"]\n",
    "            if relative_time:\n",
    "                relative_time_windows = []\n",
    "                for window in windows:\n",
    "                    start = window[0] / duration\n",
    "                    end = window[1] / duration\n",
    "\n",
    "                    if save_float:\n",
    "                        relative_time_windows.append([round(start, 2), round(end, 2)])\n",
    "                    else:\n",
    "                        relative_time_windows.append(\n",
    "                            [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                        )\n",
    "                sample[\"relevant_windows\"] = relative_time_windows\n",
    "            else:\n",
    "                sample[\"relevant_windows\"] = windows\n",
    "        else:\n",
    "            sample[\"relevant_windows\"] = [[0, 150]]  # dummy value\n",
    "\n",
    "        out.append(sample)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507365fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_QVH(train, relative_time=relative_time, save_float=save_float)\n",
    "new_val = process_QVH(val, relative_time=relative_time, save_float=save_float)\n",
    "new_test = process_QVH(\n",
    "    test, relative_time=relative_time, save_float=save_float, is_test=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9754fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_relative_float.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val_relative_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative_float_dummy.json\")\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_float.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_float_dummy.json\")\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_relative.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val_relative.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative_dummy.json\")\n",
    "else:\n",
    "    save_json(new_train, ann_root + \"/lavis/train.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_dummy.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151075f",
   "metadata": {},
   "source": [
    "# Charades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Your/path/to/Charades_v1_train.csv\", delimiter=\",\")\n",
    "test_df = pd.read_csv(\"Your/path/to/Charades_v1_test.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e05be34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 7185)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique ids\n",
    "train_ids = train_df[\"id\"].unique()\n",
    "print(len(train_ids))\n",
    "\n",
    "# randomly select 800 ids for validation\n",
    "random.seed(42)\n",
    "random.shuffle(train_ids)\n",
    "\n",
    "val_ids = train_ids[:800]\n",
    "train_ids = train_ids[800:]\n",
    "\n",
    "len(val_ids), len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"Your/path/to/Charades_STA\"\n",
    "train_path = ann_root + \"/train.txt\"\n",
    "test_path = ann_root + \"/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cd29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_charades_STA(\n",
    "    data_path, df, video_ids=None, relative_time=False, save_float=False\n",
    "):\n",
    "    # read txt and put each line into new element in list\n",
    "    with open(data_path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    out = []\n",
    "\n",
    "    qid_tracker = {}\n",
    "\n",
    "    for s in content:\n",
    "        # format \"id start end##query\"\n",
    "        s = s.split(\"##\")  # -> [id start end, query]\n",
    "        query = s[1]  # -> query\n",
    "        s = s[0]  # -> id start end\n",
    "        s = s.split(\" \")  # -> [[id], [start], [end]]\n",
    "        id = s[0]  # -> id\n",
    "\n",
    "        if video_ids is not None and id not in video_ids:\n",
    "            continue\n",
    "\n",
    "        # track the video id and increase the count\n",
    "        if id in qid_tracker:\n",
    "            qid_tracker[id] += 1\n",
    "        else:\n",
    "            qid_tracker[id] = 0\n",
    "\n",
    "        # get meta data from df using id\n",
    "        # get row with id == id\n",
    "        row = df.loc[df[\"id\"] == id]\n",
    "        values = row.values[0]\n",
    "\n",
    "        # get duration\n",
    "        duration = values[10]\n",
    "\n",
    "        # convert to float\n",
    "        s[1] = float(s[1])\n",
    "        s[2] = float(s[2])\n",
    "        if s[2] > duration:\n",
    "            s[2] = duration\n",
    "\n",
    "        if relative_time:\n",
    "            # convert to relative time\n",
    "            s[1] = s[1] / duration\n",
    "            s[2] = s[2] / duration\n",
    "\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [round(s[1], 2), round(s[2], 2)]  # -> [start, end]\n",
    "                assert window[0] >= 0 and window[1] <= 1\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [int(s[1] * 100), int(s[2] * 100)]\n",
    "                assert window[0] >= 0 and window[1] <= 100\n",
    "        else:\n",
    "            if save_float:\n",
    "                # For float conversion\n",
    "                window = [float(s[1]), float(s[2])]  # -> [start, end]\n",
    "            else:\n",
    "                # For int conversion -> round to nearest int\n",
    "                window = [round(float(s[1])), round(float(s[2]))]\n",
    "\n",
    "        # get objects\n",
    "        objects = values[7]\n",
    "        # only split if objects is not nan or contains ; (which means multiple objects)\n",
    "        try:\n",
    "            objects = objects.split(\";\")\n",
    "        except:\n",
    "            print(\"no objects: \", objects, \" for id: \", id)\n",
    "            objects = []\n",
    "\n",
    "        out.append(\n",
    "            {\n",
    "                \"id\": id,\n",
    "                \"qid\": \"CharadesSTA_\" + str(id) + \"_\" + str(qid_tracker[id]),\n",
    "                \"query\": query,\n",
    "                \"window\": [window],\n",
    "                \"duration\": duration,\n",
    "                \"objects\": objects,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60e9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no objects:  nan  for id:  ZWVO3\n",
      "no objects:  nan  for id:  ZWVO3\n",
      "no objects:  nan  for id:  5U1IT\n",
      "no objects:  nan  for id:  5U1IT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11166, 1242, 3720)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(\n",
    "    train_path, train_df, train_ids, relative_time=relative_time, save_float=save_float\n",
    ")\n",
    "val = process_charades_STA(train_path, train_df, val_ids, save_float=save_float)\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = qa[\"id\"]\n",
    "    qa_dict[\"qid\"] = qa[\"qid\"]\n",
    "    qa_dict[\"query\"] = qa[\"query\"]\n",
    "    qa_dict[\"duration\"] = qa[\"duration\"]\n",
    "    qa_dict[\"relevant_windows\"] = qa[\"window\"]\n",
    "    qa_dict[\"objects\"] = qa[\"objects\"]\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(val):\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = qa[\"id\"]\n",
    "    qa_dict[\"qid\"] = qa[\"qid\"]\n",
    "    qa_dict[\"query\"] = qa[\"query\"]\n",
    "    qa_dict[\"duration\"] = qa[\"duration\"]\n",
    "    qa_dict[\"relevant_windows\"] = qa[\"window\"]\n",
    "    qa_dict[\"objects\"] = qa[\"objects\"]\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = qa[\"id\"]\n",
    "    qa_dict[\"qid\"] = qa[\"qid\"]\n",
    "    qa_dict[\"query\"] = qa[\"query\"]\n",
    "    qa_dict[\"duration\"] = qa[\"duration\"]\n",
    "    qa_dict[\"relevant_windows\"] = qa[\"window\"]\n",
    "    qa_dict[\"objects\"] = qa[\"objects\"]\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978bc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/new_train_relative_float.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/new_val_relative_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative_float.json\")\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/new_train_float.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/new_val_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_float.json\")\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/new_train_relative.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/new_val_relative.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative.json\")\n",
    "else:\n",
    "    save_json(new_train, ann_root + \"/lavis/new_train.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/new_val.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72299f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no objects:  nan  for id:  ZWVO3\n",
      "no objects:  nan  for id:  ZWVO3\n",
      "no objects:  nan  for id:  5U1IT\n",
      "no objects:  nan  for id:  5U1IT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12408, 3720)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For processing without the custom data slipt, i.e. having only the original train and test split\n",
    "\n",
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "train = process_charades_STA(\n",
    "    train_path, train_df, None, relative_time=relative_time, save_float=save_float\n",
    ")\n",
    "test = process_charades_STA(test_path, test_df, save_float=save_float)\n",
    "\n",
    "new_train = []\n",
    "new_val = []\n",
    "new_test = []\n",
    "for i, qa in enumerate(train):\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = qa[\"id\"]\n",
    "    qa_dict[\"qid\"] = qa[\"qid\"]\n",
    "    qa_dict[\"query\"] = qa[\"query\"]\n",
    "    qa_dict[\"duration\"] = qa[\"duration\"]\n",
    "    qa_dict[\"relevant_windows\"] = qa[\"window\"]\n",
    "    qa_dict[\"objects\"] = qa[\"objects\"]\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for i, qa in enumerate(test):\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = qa[\"id\"]\n",
    "    qa_dict[\"qid\"] = qa[\"qid\"]\n",
    "    qa_dict[\"query\"] = qa[\"query\"]\n",
    "    qa_dict[\"duration\"] = qa[\"duration\"]\n",
    "    qa_dict[\"relevant_windows\"] = qa[\"window\"]\n",
    "    qa_dict[\"objects\"] = qa[\"objects\"]\n",
    "    new_test.append(qa_dict)\n",
    "\n",
    "len(new_train), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_relative_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative_float.json\")\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_float.json\")\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_relative.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative.json\")\n",
    "else:\n",
    "    save_json(new_train, ann_root + \"/lavis/train.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f67a5",
   "metadata": {},
   "source": [
    "# NextQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"Your/path/to/NExT_QA\"\n",
    "raw_root = \"Your/path/to/raw/NExT\"\n",
    "train_path = ann_root + \"/nextqa/train.csv\"\n",
    "val_path = ann_root + \"/nextqa/val.csv\"\n",
    "test_path = ann_root + \"/nextqa/test.csv\"\n",
    "map_vid_vidorID_path = ann_root + \"/map_vid_vidorID.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv(train_path, delimiter=\",\")\n",
    "raw_val = pd.read_csv(val_path, delimiter=\",\")\n",
    "train = []\n",
    "val = []\n",
    "key = [\"video\", \"question\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"answer\", \"qid\", \"type\"]\n",
    "for i in range(len(raw_train)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_train.iloc[i][k]\n",
    "    train.append(data)\n",
    "\n",
    "for i in range(len(raw_val)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_val.iloc[i][k]\n",
    "    val.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8134eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_map = load_json(map_vid_vidorID_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cf966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(vid):\n",
    "    vid_path = raw_root + \"/\" + vid_map[vid] + \".mp4\"\n",
    "    clip = VideoFileClip(vid_path)\n",
    "    return clip.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = []\n",
    "new_val = []\n",
    "\n",
    "print(\"Processing train and val data...\")\n",
    "print(\n",
    "    \"This could lake a while (100 min), because we need to extract the video durations for each video\"\n",
    ")\n",
    "\n",
    "for qa in train:\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = vid_map[str(qa[\"video\"])]\n",
    "    qa_dict[\"duration\"] = get_video_duration(str(qa[\"video\"]))\n",
    "    qa_dict[\"num_option\"] = int(5)\n",
    "    qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video\"]), str(qa[\"qid\"])])\n",
    "    for i in range(5):\n",
    "        qa_dict[\"a{}\".format(str(i))] = qa[\"a{}\".format(str(i))] + \".\"\n",
    "    qa_dict[\"answer\"] = int(qa[\"answer\"])\n",
    "    qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "    new_train.append(qa_dict)\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = vid_map[str(qa[\"video\"])]\n",
    "    qa_dict[\"duration\"] = get_video_duration(str(qa[\"video\"]))\n",
    "    qa_dict[\"num_option\"] = int(5)\n",
    "    qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video\"]), str(qa[\"qid\"])])\n",
    "    for i in range(5):\n",
    "        qa_dict[\"a{}\".format(str(i))] = qa[\"a{}\".format(str(i))] + \".\"\n",
    "    qa_dict[\"answer\"] = int(qa[\"answer\"])\n",
    "    qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "    new_val.append(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_train, ann_root + \"/lavis/train.json\")\n",
    "save_json(new_val, ann_root + \"/lavis/val.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c30052",
   "metadata": {},
   "source": [
    "# NExT-GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"Your/path/to/NExT_QA\"\n",
    "raw_root = \"Your/path/to/raw/NExT\"\n",
    "# train_path = ann_root + '/nextgqa/train.csv'\n",
    "val_path = ann_root + \"/nextgqa/val.csv\"\n",
    "test_path = ann_root + \"/nextgqa/test.csv\"\n",
    "map_vid_vidorID_path = ann_root + \"/map_vid_vidorID.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a239480",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_val = pd.read_csv(val_path, delimiter=\",\")\n",
    "raw_test = pd.read_csv(test_path, delimiter=\",\")\n",
    "val = []\n",
    "test = []\n",
    "key = [\"video_id\", \"question\", \"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"answer\", \"qid\", \"type\"]\n",
    "\n",
    "for i in range(len(raw_val)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_val.iloc[i][k]\n",
    "    val.append(data)\n",
    "\n",
    "for i in range(len(raw_test)):\n",
    "    data = {}\n",
    "    for k in key:\n",
    "        data[k] = raw_test.iloc[i][k]\n",
    "    test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22c038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_map = load_json(map_vid_vidorID_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_val = load_json(ann_root + \"/nextgqa/gsub_val.json\")\n",
    "time_test = load_json(ann_root + \"/nextgqa/gsub_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_duration(vid):\n",
    "    vid_path = raw_root + \"/\" + vid_map[vid] + \".mp4\"\n",
    "    clip = VideoFileClip(vid_path)\n",
    "    return clip.duration\n",
    "\n",
    "\n",
    "def get_answer_idx(answer, options):\n",
    "    for i, option in enumerate(options):\n",
    "        if option == answer:\n",
    "            return i\n",
    "    print(\"Error: answer not in options\")\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a40d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moment_timespan(time_data, video_id, qid):\n",
    "    data = time_data[str(video_id)]\n",
    "    location = data[\"location\"][str(qid)]\n",
    "    duration = data[\"duration\"]\n",
    "\n",
    "    return location, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val = []\n",
    "new_test = []\n",
    "\n",
    "# print('Processing train and val data...')\n",
    "# print('This could lake a while (100 min), because we need to extract the video durations for each video')\n",
    "\n",
    "for qa in val:\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = vid_map[str(qa[\"video_id\"])]\n",
    "    # qa_dict['duration'] = get_video_duration(str(qa['video_id']))\n",
    "    qa_dict[\"num_option\"] = int(5)\n",
    "    qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video_id\"]), str(qa[\"qid\"])])\n",
    "    for i in range(5):\n",
    "        qa_dict[\"a{}\".format(str(i))] = qa[\"a{}\".format(str(i))] + \".\"\n",
    "    qa_dict[\"answer\"] = get_answer_idx(\n",
    "        qa[\"answer\"], [qa[\"a0\"], qa[\"a1\"], qa[\"a2\"], qa[\"a3\"], qa[\"a4\"]]\n",
    "    )\n",
    "    qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "\n",
    "    ### GQA specific\n",
    "    relevant_windows, duration = get_moment_timespan(\n",
    "        time_val, qa[\"video_id\"], qa[\"qid\"]\n",
    "    )\n",
    "    qa_dict[\"relevant_windows\"] = relevant_windows\n",
    "    qa_dict[\"duration\"] = duration\n",
    "\n",
    "    new_val.append(qa_dict)\n",
    "\n",
    "for qa in test:\n",
    "    qa_dict = {}\n",
    "    qa_dict[\"video\"] = vid_map[str(qa[\"video_id\"])]\n",
    "    # qa_dict['duration'] = get_video_duration(str(qa['video_id']))\n",
    "    qa_dict[\"num_option\"] = int(5)\n",
    "    qa_dict[\"qid\"] = \"_\".join([qa[\"type\"], str(qa[\"video_id\"]), str(qa[\"qid\"])])\n",
    "    for i in range(5):\n",
    "        qa_dict[\"a{}\".format(str(i))] = qa[\"a{}\".format(str(i))] + \".\"\n",
    "    qa_dict[\"answer\"] = get_answer_idx(\n",
    "        qa[\"answer\"], [qa[\"a0\"], qa[\"a1\"], qa[\"a2\"], qa[\"a3\"], qa[\"a4\"]]\n",
    "    )\n",
    "    qa_dict[\"question\"] = qa[\"question\"] + \"?\"\n",
    "\n",
    "    ### GQA specific\n",
    "    relevant_windows, duration = get_moment_timespan(\n",
    "        time_test, qa[\"video_id\"], qa[\"qid\"]\n",
    "    )\n",
    "    qa_dict[\"relevant_windows\"] = relevant_windows\n",
    "    qa_dict[\"duration\"] = duration\n",
    "\n",
    "    new_test.append(qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627659e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(new_val, ann_root + \"/lavis/nextgqa/val.json\")\n",
    "save_json(new_test, ann_root + \"/lavis/nextgqa/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b041cad",
   "metadata": {},
   "source": [
    "# ActivityNet Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43920332",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_root = \"Your/path/to/ActivityNet\"\n",
    "train_path = os.path.join(ann_root, \"train.json\")\n",
    "val_path = os.path.join(ann_root, \"val_1.json\")\n",
    "test_path = os.path.join(ann_root, \"val_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_json(train_path)\n",
    "val = load_json(val_path)\n",
    "test = load_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee346274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activitynet(data, relative_time=False, save_float=False):\n",
    "    out = []\n",
    "\n",
    "    for video_id, sample in data.items():\n",
    "        duration = sample[\"duration\"]\n",
    "        sentences = sample[\"sentences\"]\n",
    "        timestamps = sample[\"timestamps\"]\n",
    "        for j, (start, end) in enumerate(timestamps):\n",
    "\n",
    "            if relative_time:\n",
    "                # convert to relative time\n",
    "                start = start / duration\n",
    "                end = end / duration\n",
    "\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [round(start, 2), round(end, 2)]\n",
    "                    assert window[0] >= 0 and window[1] <= 1\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [int(round(start, 2) * 100), int(round(end, 2) * 100)]\n",
    "                    assert window[0] >= 0 and window[1] <= 100\n",
    "            else:\n",
    "                if save_float:\n",
    "                    # For float conversion\n",
    "                    window = [float(start), float(end)]\n",
    "                else:\n",
    "                    # For int conversion -> round to nearest int\n",
    "                    window = [round(float(start)), round(float(end))]\n",
    "\n",
    "            new_sample = {\n",
    "                \"video\": video_id,\n",
    "                \"qid\": f\"ActivityNet_{video_id}_{j}\",\n",
    "                \"query\": sentences[j],\n",
    "                \"duration\": duration,\n",
    "                \"relevant_windows\": [window],\n",
    "            }\n",
    "\n",
    "            out.append(new_sample)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_float = False\n",
    "relative_time = False\n",
    "\n",
    "new_train = process_activitynet(\n",
    "    train, relative_time=relative_time, save_float=save_float\n",
    ")\n",
    "new_val = process_activitynet(val, save_float=save_float)\n",
    "new_test = process_activitynet(test, save_float=save_float)\n",
    "\n",
    "len(new_train), len(new_val), len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "if save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_relative_float.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val_relative_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative_float.json\")\n",
    "elif save_float and not relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_float.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val_float.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_float.json\")\n",
    "elif not save_float and relative_time:\n",
    "    save_json(new_train, ann_root + \"/lavis/train_relative.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val_relative.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test_relative.json\")\n",
    "else:\n",
    "    save_json(new_train, ann_root + \"/lavis/train.json\")\n",
    "    save_json(new_val, ann_root + \"/lavis/val.json\")\n",
    "    save_json(new_test, ann_root + \"/lavis/test.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
